{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import shelve\n",
    "import random\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import model_1\n",
    "import utils\n",
    "_ = importlib.reload(model_1)\n",
    "_ = importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "BATCH_SIZE = 10\n",
    "SHELVE_PATH = 'data/processed-data/data-1/db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = model_1.ShelveDataset(SHELVE_PATH)\n",
    "dl = DataLoader(\n",
    "    ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=model_1.ShelveDataset.collate_fn, \n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_1.AvgPoolingCnn().to(DEVICE)\n",
    "# model = torch.load('models/SCS-model-dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100  ][Batch 12 ]\tLoss: 1.6833\tAccuracy: [0.95384615 0.93076923 0.81538462 0.68461538 0.75384615] [0.8277]\n",
      "[Epoch 1/100  ][Batch 24 ]\tLoss: 1.6922\tAccuracy: [0.956 0.928 0.816 0.656 0.76 ] [0.8232]\n",
      "[Epoch 1/100  ][Batch 36 ]\tLoss: 2.0276\tAccuracy: [0.95945946 0.92972973 0.81351351 0.66216216 0.74594595] [0.8222]\n",
      "[Epoch 1/100  ][Batch 48 ]\tLoss: 1.7320\tAccuracy: [0.96326531 0.93469388 0.81836735 0.68979592 0.74897959] [0.8310]\n",
      "[Epoch 1/100  ][Batch 60 ]\tLoss: 1.6094\tAccuracy: [0.96885246 0.94098361 0.82295082 0.70491803 0.74262295] [0.8361]\n",
      "[Epoch 1/100  ][Batch 72 ]\tLoss: 1.4325\tAccuracy: [0.96849315 0.94794521 0.8260274  0.72191781 0.75616438] [0.8441]\n",
      "[Epoch 1/100  ][Batch 84 ]\tLoss: 1.1041\tAccuracy: [0.96941176 0.94235294 0.83647059 0.73411765 0.75882353] [0.8482]\n",
      "[Epoch 1/100  ][Batch 96 ]\tLoss: 1.7570\tAccuracy: [0.97319588 0.94742268 0.84536082 0.73092784 0.76701031] [0.8528]\n",
      "[Epoch 1/100  ][Batch 108]\tLoss: 1.9675\tAccuracy: [0.97431193 0.9440367  0.84311927 0.73119266 0.76605505] [0.8517]\n",
      "[Epoch 1/100  ][Batch 120]\tLoss: 2.4987\tAccuracy: [0.97272727 0.9446281  0.83966942 0.7322314  0.7677686 ] [0.8514]\n",
      "[Epoch 1/100  ][Batch 132]\tLoss: 1.6164\tAccuracy: [0.97218045 0.9406015  0.84360902 0.73533835 0.76992481] [0.8523]\n",
      "[Epoch 1/100  ][Batch 144]\tLoss: 1.9947\tAccuracy: [0.97172414 0.93586207 0.84413793 0.74206897 0.77310345] [0.8534]\n",
      "[Epoch 1/100  ][Batch 156]\tLoss: 1.3567\tAccuracy: [0.97197452 0.93694268 0.84840764 0.75031847 0.77834395] [0.8572]\n",
      "[Epoch 1/100  ][Batch 168]\tLoss: 1.1965\tAccuracy: [0.97337278 0.93786982 0.85147929 0.75207101 0.77988166] [0.8589]\n",
      "[Epoch 1/100  ][Batch 180]\tLoss: 1.6169\tAccuracy: [0.97348066 0.93535912 0.84917127 0.75248619 0.78176796] [0.8585]\n",
      "[Epoch 1/100  ][Batch 192]\tLoss: 1.0554\tAccuracy: [0.97409326 0.93626943 0.85233161 0.75440415 0.78238342] [0.8599]\n",
      "[Epoch 2/100  ][Batch 12 ]\tLoss: 1.4122\tAccuracy: [0.99230769 0.93076923 0.88461538 0.79230769 0.83076923] [0.8862]\n",
      "[Epoch 2/100  ][Batch 24 ]\tLoss: 2.3051\tAccuracy: [0.972 0.944 0.86  0.796 0.82 ] [0.8784]\n",
      "[Epoch 2/100  ][Batch 36 ]\tLoss: 2.1940\tAccuracy: [0.97567568 0.93783784 0.85945946 0.79189189 0.80540541] [0.8741]\n",
      "[Epoch 2/100  ][Batch 48 ]\tLoss: 1.4321\tAccuracy: [0.9755102  0.92857143 0.85306122 0.78979592 0.80204082] [0.8698]\n",
      "[Epoch 2/100  ][Batch 60 ]\tLoss: 2.1511\tAccuracy: [0.97377049 0.93442623 0.86065574 0.7852459  0.80655738] [0.8721]\n",
      "[Epoch 2/100  ][Batch 72 ]\tLoss: 1.1096\tAccuracy: [0.97534247 0.9369863  0.86986301 0.78493151 0.80958904] [0.8753]\n",
      "[Epoch 2/100  ][Batch 84 ]\tLoss: 2.2080\tAccuracy: [0.97764706 0.94352941 0.87176471 0.79529412 0.81294118] [0.8802]\n",
      "[Epoch 2/100  ][Batch 96 ]\tLoss: 2.0285\tAccuracy: [0.97835052 0.9443299  0.87628866 0.79381443 0.81443299] [0.8814]\n",
      "[Epoch 2/100  ][Batch 108]\tLoss: 2.8330\tAccuracy: [0.97889908 0.9440367  0.86605505 0.78990826 0.81284404] [0.8783]\n",
      "[Epoch 2/100  ][Batch 120]\tLoss: 1.6422\tAccuracy: [0.9785124  0.94545455 0.87190083 0.78677686 0.81157025] [0.8788]\n",
      "[Epoch 2/100  ][Batch 132]\tLoss: 1.9375\tAccuracy: [0.97894737 0.9443609  0.87142857 0.78571429 0.81052632] [0.8782]\n",
      "[Epoch 2/100  ][Batch 144]\tLoss: 1.5564\tAccuracy: [0.98       0.94551724 0.87172414 0.78275862 0.80827586] [0.8777]\n",
      "[Epoch 2/100  ][Batch 156]\tLoss: 0.8691\tAccuracy: [0.97898089 0.94458599 0.87006369 0.78216561 0.81019108] [0.8772]\n",
      "[Epoch 2/100  ][Batch 168]\tLoss: 1.5539\tAccuracy: [0.98047337 0.94260355 0.86923077 0.78284024 0.81005917] [0.8770]\n",
      "[Epoch 2/100  ][Batch 180]\tLoss: 1.1637\tAccuracy: [0.98066298 0.94254144 0.87071823 0.7839779  0.80939227] [0.8775]\n",
      "[Epoch 2/100  ][Batch 192]\tLoss: 1.6293\tAccuracy: [0.98186528 0.94507772 0.87150259 0.78445596 0.80880829] [0.8783]\n",
      "[Epoch 3/100  ][Batch 12 ]\tLoss: 0.9644\tAccuracy: [0.99230769 0.94615385 0.88461538 0.81538462 0.81538462] [0.8908]\n",
      "[Epoch 3/100  ][Batch 24 ]\tLoss: 0.8857\tAccuracy: [0.996 0.948 0.892 0.776 0.808] [0.8840]\n",
      "[Epoch 3/100  ][Batch 36 ]\tLoss: 1.4693\tAccuracy: [0.99189189 0.95405405 0.89189189 0.77027027 0.82162162] [0.8859]\n",
      "[Epoch 3/100  ][Batch 48 ]\tLoss: 1.4397\tAccuracy: [0.98367347 0.95102041 0.89183673 0.77142857 0.81428571] [0.8824]\n",
      "[Epoch 3/100  ][Batch 60 ]\tLoss: 1.7174\tAccuracy: [0.97868852 0.95245902 0.89672131 0.78196721 0.82295082] [0.8866]\n",
      "[Epoch 3/100  ][Batch 72 ]\tLoss: 1.4059\tAccuracy: [0.97945205 0.94657534 0.89041096 0.78630137 0.82054795] [0.8847]\n",
      "[Epoch 3/100  ][Batch 84 ]\tLoss: 1.1063\tAccuracy: [0.98235294 0.94941176 0.88941176 0.79882353 0.82352941] [0.8887]\n",
      "[Epoch 3/100  ][Batch 96 ]\tLoss: 1.4404\tAccuracy: [0.97938144 0.94845361 0.88762887 0.80103093 0.8185567 ] [0.8870]\n",
      "[Epoch 3/100  ][Batch 108]\tLoss: 1.0417\tAccuracy: [0.97889908 0.94954128 0.88715596 0.80642202 0.81834862] [0.8881]\n",
      "[Epoch 3/100  ][Batch 120]\tLoss: 0.6960\tAccuracy: [0.98016529 0.95041322 0.89090909 0.80826446 0.8231405 ] [0.8906]\n",
      "[Epoch 3/100  ][Batch 132]\tLoss: 1.6448\tAccuracy: [0.98195489 0.95112782 0.89097744 0.80902256 0.81954887] [0.8905]\n",
      "[Epoch 3/100  ][Batch 144]\tLoss: 1.0472\tAccuracy: [0.98275862 0.95103448 0.88758621 0.80965517 0.81517241] [0.8892]\n",
      "[Epoch 3/100  ][Batch 156]\tLoss: 2.0216\tAccuracy: [0.98152866 0.95031847 0.88216561 0.8089172  0.81910828] [0.8884]\n",
      "[Epoch 3/100  ][Batch 168]\tLoss: 2.0804\tAccuracy: [0.98224852 0.95029586 0.88047337 0.80650888 0.81893491] [0.8877]\n",
      "[Epoch 3/100  ][Batch 180]\tLoss: 1.4253\tAccuracy: [0.98287293 0.95027624 0.87734807 0.80441989 0.82044199] [0.8871]\n",
      "[Epoch 3/100  ][Batch 192]\tLoss: 1.5969\tAccuracy: [0.98393782 0.94974093 0.8761658  0.80259067 0.82020725] [0.8865]\n",
      "[Epoch 4/100  ][Batch 12 ]\tLoss: 0.9892\tAccuracy: [0.98461538 0.96153846 0.89230769 0.84615385 0.83076923] [0.9031]\n",
      "[Epoch 4/100  ][Batch 24 ]\tLoss: 1.4418\tAccuracy: [0.984 0.96  0.9   0.812 0.848] [0.9008]\n",
      "[Epoch 4/100  ][Batch 36 ]\tLoss: 1.5807\tAccuracy: [0.98648649 0.95945946 0.88648649 0.7972973  0.83783784] [0.8935]\n",
      "[Epoch 4/100  ][Batch 48 ]\tLoss: 1.2011\tAccuracy: [0.98571429 0.96122449 0.88979592 0.80816327 0.83877551] [0.8967]\n",
      "[Epoch 4/100  ][Batch 60 ]\tLoss: 1.1492\tAccuracy: [0.9852459  0.95737705 0.87704918 0.80819672 0.83278689] [0.8921]\n",
      "[Epoch 4/100  ][Batch 72 ]\tLoss: 0.8386\tAccuracy: [0.98767123 0.95068493 0.87808219 0.81232877 0.83972603] [0.8937]\n",
      "[Epoch 4/100  ][Batch 84 ]\tLoss: 0.9513\tAccuracy: [0.98941176 0.95529412 0.88       0.81764706 0.84588235] [0.8976]\n",
      "[Epoch 4/100  ][Batch 96 ]\tLoss: 0.7054\tAccuracy: [0.98556701 0.95257732 0.88247423 0.81752577 0.84639175] [0.8969]\n",
      "[Epoch 4/100  ][Batch 108]\tLoss: 1.2482\tAccuracy: [0.98623853 0.9559633  0.8853211  0.82018349 0.84495413] [0.8985]\n",
      "[Epoch 4/100  ][Batch 120]\tLoss: 0.7057\tAccuracy: [0.98677686 0.95371901 0.88760331 0.82644628 0.83966942] [0.8988]\n",
      "[Epoch 4/100  ][Batch 132]\tLoss: 1.4315\tAccuracy: [0.98796992 0.95338346 0.89172932 0.82330827 0.83759398] [0.8988]\n",
      "[Epoch 4/100  ][Batch 144]\tLoss: 1.3752\tAccuracy: [0.98827586 0.95448276 0.89241379 0.82689655 0.83655172] [0.8997]\n",
      "[Epoch 4/100  ][Batch 156]\tLoss: 1.1556\tAccuracy: [0.9866242  0.9522293  0.8866242  0.82993631 0.83057325] [0.8972]\n",
      "[Epoch 4/100  ][Batch 168]\tLoss: 1.4469\tAccuracy: [0.98698225 0.9556213  0.88579882 0.83431953 0.8295858 ] [0.8985]\n",
      "[Epoch 4/100  ][Batch 180]\tLoss: 0.9890\tAccuracy: [0.9878453  0.9558011  0.88674033 0.83425414 0.82983425] [0.8989]\n",
      "[Epoch 4/100  ][Batch 192]\tLoss: 1.7239\tAccuracy: [0.98860104 0.95440415 0.8880829  0.83316062 0.83005181] [0.8989]\n",
      "[Epoch 5/100  ][Batch 12 ]\tLoss: 1.1034\tAccuracy: [0.97692308 0.95384615 0.93076923 0.77692308 0.84615385] [0.8969]\n",
      "[Epoch 5/100  ][Batch 24 ]\tLoss: 1.4071\tAccuracy: [0.988 0.956 0.92  0.78  0.808] [0.8904]\n",
      "[Epoch 5/100  ][Batch 36 ]\tLoss: 1.9020\tAccuracy: [0.99189189 0.95945946 0.92432432 0.79459459 0.80810811] [0.8957]\n",
      "[Epoch 5/100  ][Batch 48 ]\tLoss: 0.5496\tAccuracy: [0.99183673 0.96122449 0.9122449  0.78571429 0.81836735] [0.8939]\n",
      "[Epoch 5/100  ][Batch 60 ]\tLoss: 1.4596\tAccuracy: [0.99180328 0.96393443 0.90983607 0.79836066 0.82786885] [0.8984]\n",
      "[Epoch 5/100  ][Batch 72 ]\tLoss: 1.3476\tAccuracy: [0.99178082 0.96438356 0.90273973 0.80547945 0.82739726] [0.8984]\n",
      "[Epoch 5/100  ][Batch 84 ]\tLoss: 0.7179\tAccuracy: [0.99294118 0.96       0.90352941 0.81294118 0.83647059] [0.9012]\n",
      "[Epoch 5/100  ][Batch 96 ]\tLoss: 0.6774\tAccuracy: [0.99175258 0.95876289 0.90412371 0.82474227 0.84329897] [0.9045]\n",
      "[Epoch 5/100  ][Batch 108]\tLoss: 1.6245\tAccuracy: [0.99174312 0.95321101 0.89908257 0.82110092 0.8412844 ] [0.9013]\n",
      "[Epoch 5/100  ][Batch 120]\tLoss: 1.0896\tAccuracy: [0.99173554 0.95206612 0.89834711 0.8231405  0.84297521] [0.9017]\n",
      "[Epoch 5/100  ][Batch 132]\tLoss: 1.1969\tAccuracy: [0.99172932 0.95112782 0.89548872 0.82481203 0.8406015 ] [0.9008]\n",
      "[Epoch 5/100  ][Batch 144]\tLoss: 1.3663\tAccuracy: [0.99241379 0.95310345 0.89724138 0.81931034 0.84137931] [0.9007]\n",
      "[Epoch 5/100  ][Batch 156]\tLoss: 1.1015\tAccuracy: [0.99235669 0.95605096 0.89617834 0.81910828 0.84585987] [0.9019]\n",
      "[Epoch 5/100  ][Batch 168]\tLoss: 0.7812\tAccuracy: [0.99230769 0.9556213  0.89349112 0.81715976 0.84201183] [0.9001]\n",
      "[Epoch 5/100  ][Batch 180]\tLoss: 0.8725\tAccuracy: [0.99171271 0.95524862 0.89502762 0.82099448 0.84309392] [0.9012]\n",
      "[Epoch 5/100  ][Batch 192]\tLoss: 1.5428\tAccuracy: [0.99067358 0.95595855 0.89481865 0.8238342  0.84404145] [0.9019]\n",
      "[Epoch 6/100  ][Batch 12 ]\tLoss: 1.0190\tAccuracy: [0.99230769 0.96153846 0.94615385 0.89230769 0.86153846] [0.9308]\n",
      "[Epoch 6/100  ][Batch 24 ]\tLoss: 0.4257\tAccuracy: [0.988 0.964 0.928 0.848 0.852] [0.9160]\n",
      "[Epoch 6/100  ][Batch 36 ]\tLoss: 2.0219\tAccuracy: [0.98918919 0.97027027 0.92162162 0.85675676 0.84324324] [0.9162]\n",
      "[Epoch 6/100  ][Batch 48 ]\tLoss: 1.3848\tAccuracy: [0.9877551  0.96734694 0.91632653 0.85918367 0.83877551] [0.9139]\n",
      "[Epoch 6/100  ][Batch 60 ]\tLoss: 0.7097\tAccuracy: [0.98852459 0.96885246 0.9147541  0.86557377 0.84098361] [0.9157]\n",
      "[Epoch 6/100  ][Batch 72 ]\tLoss: 1.3893\tAccuracy: [0.99041096 0.96575342 0.90958904 0.86986301 0.84520548] [0.9162]\n",
      "[Epoch 6/100  ][Batch 84 ]\tLoss: 1.0189\tAccuracy: [0.99058824 0.96470588 0.91176471 0.86705882 0.85529412] [0.9179]\n",
      "[Epoch 6/100  ][Batch 96 ]\tLoss: 1.4742\tAccuracy: [0.99175258 0.96391753 0.90927835 0.86391753 0.85876289] [0.9175]\n",
      "[Epoch 6/100  ][Batch 108]\tLoss: 1.2026\tAccuracy: [0.99174312 0.96055046 0.90733945 0.86055046 0.86146789] [0.9163]\n",
      "[Epoch 6/100  ][Batch 120]\tLoss: 0.5009\tAccuracy: [0.99173554 0.96115702 0.90991736 0.8661157  0.86280992] [0.9183]\n",
      "[Epoch 6/100  ][Batch 132]\tLoss: 1.2986\tAccuracy: [0.99022556 0.96240602 0.90526316 0.8593985  0.86165414] [0.9158]\n",
      "[Epoch 6/100  ][Batch 144]\tLoss: 0.8630\tAccuracy: [0.98965517 0.95931034 0.90068966 0.85172414 0.86137931] [0.9126]\n",
      "[Epoch 6/100  ][Batch 156]\tLoss: 1.5707\tAccuracy: [0.98917197 0.95923567 0.89936306 0.85286624 0.86178344] [0.9125]\n",
      "[Epoch 6/100  ][Batch 168]\tLoss: 2.4956\tAccuracy: [0.98934911 0.9591716  0.89881657 0.85088757 0.86153846] [0.9120]\n",
      "[Epoch 6/100  ][Batch 180]\tLoss: 0.8705\tAccuracy: [0.98895028 0.95966851 0.89834254 0.84972376 0.86298343] [0.9119]\n",
      "[Epoch 6/100  ][Batch 192]\tLoss: 0.6926\tAccuracy: [0.98860104 0.96010363 0.9015544  0.8507772  0.86217617] [0.9126]\n",
      "[Epoch 7/100  ][Batch 12 ]\tLoss: 1.2827\tAccuracy: [0.99230769 0.96153846 0.93846154 0.86923077 0.87692308] [0.9277]\n",
      "[Epoch 7/100  ][Batch 24 ]\tLoss: 1.5835\tAccuracy: [0.988 0.968 0.92  0.852 0.86 ] [0.9176]\n",
      "[Epoch 7/100  ][Batch 36 ]\tLoss: 0.5204\tAccuracy: [0.98918919 0.96216216 0.94054054 0.86756757 0.87567568] [0.9270]\n",
      "[Epoch 7/100  ][Batch 48 ]\tLoss: 1.0465\tAccuracy: [0.9877551  0.96326531 0.93061224 0.85510204 0.87959184] [0.9233]\n",
      "[Epoch 7/100  ][Batch 60 ]\tLoss: 1.1635\tAccuracy: [0.98852459 0.96065574 0.92786885 0.85901639 0.87704918] [0.9226]\n",
      "[Epoch 7/100  ][Batch 72 ]\tLoss: 0.5162\tAccuracy: [0.99041096 0.9630137  0.92465753 0.86712329 0.88493151] [0.9260]\n",
      "[Epoch 7/100  ][Batch 84 ]\tLoss: 0.3640\tAccuracy: [0.98941176 0.96       0.92823529 0.88       0.88235294] [0.9280]\n",
      "[Epoch 7/100  ][Batch 96 ]\tLoss: 0.9739\tAccuracy: [0.99072165 0.96082474 0.92371134 0.88247423 0.88762887] [0.9291]\n",
      "[Epoch 7/100  ][Batch 108]\tLoss: 0.7084\tAccuracy: [0.99174312 0.96238532 0.91926606 0.88348624 0.8853211 ] [0.9284]\n",
      "[Epoch 7/100  ][Batch 120]\tLoss: 0.6773\tAccuracy: [0.99173554 0.96280992 0.92066116 0.88181818 0.88347107] [0.9281]\n",
      "[Epoch 7/100  ][Batch 132]\tLoss: 0.9854\tAccuracy: [0.9924812  0.96315789 0.92030075 0.88195489 0.87894737] [0.9274]\n",
      "[Epoch 7/100  ][Batch 144]\tLoss: 1.0967\tAccuracy: [0.99172414 0.96482759 0.91931034 0.88275862 0.87241379] [0.9262]\n",
      "[Epoch 7/100  ][Batch 156]\tLoss: 0.6583\tAccuracy: [0.98980892 0.96433121 0.91847134 0.88280255 0.87133758] [0.9254]\n",
      "[Epoch 7/100  ][Batch 168]\tLoss: 0.6233\tAccuracy: [0.98934911 0.96449704 0.91775148 0.87928994 0.86923077] [0.9240]\n",
      "[Epoch 7/100  ][Batch 180]\tLoss: 0.8814\tAccuracy: [0.98950276 0.96574586 0.91767956 0.88066298 0.86685083] [0.9241]\n",
      "[Epoch 7/100  ][Batch 192]\tLoss: 0.9693\tAccuracy: [0.99015544 0.96528497 0.91865285 0.87668394 0.86735751] [0.9236]\n",
      "[Epoch 8/100  ][Batch 12 ]\tLoss: 1.2324\tAccuracy: [0.98461538 0.96923077 0.93846154 0.89230769 0.87692308] [0.9323]\n",
      "[Epoch 8/100  ][Batch 24 ]\tLoss: 0.7964\tAccuracy: [0.988 0.972 0.944 0.88  0.884] [0.9336]\n",
      "[Epoch 8/100  ][Batch 36 ]\tLoss: 0.7461\tAccuracy: [0.99189189 0.97837838 0.94054054 0.89189189 0.88378378] [0.9373]\n",
      "[Epoch 8/100  ][Batch 48 ]\tLoss: 1.1205\tAccuracy: [0.98163265 0.97142857 0.93469388 0.87755102 0.87142857] [0.9273]\n",
      "[Epoch 8/100  ][Batch 60 ]\tLoss: 0.5275\tAccuracy: [0.98360656 0.97540984 0.93442623 0.87868852 0.88360656] [0.9311]\n",
      "[Epoch 8/100  ][Batch 72 ]\tLoss: 1.4660\tAccuracy: [0.98493151 0.97534247 0.93835616 0.87534247 0.88493151] [0.9318]\n",
      "[Epoch 8/100  ][Batch 84 ]\tLoss: 0.7979\tAccuracy: [0.98705882 0.97647059 0.93411765 0.88117647 0.88235294] [0.9322]\n",
      "[Epoch 8/100  ][Batch 96 ]\tLoss: 1.4333\tAccuracy: [0.98865979 0.97319588 0.93505155 0.88247423 0.88041237] [0.9320]\n",
      "[Epoch 8/100  ][Batch 108]\tLoss: 0.9362\tAccuracy: [0.98990826 0.9733945  0.93302752 0.88623853 0.87431193] [0.9314]\n",
      "[Epoch 8/100  ][Batch 120]\tLoss: 0.5474\tAccuracy: [0.99090909 0.97272727 0.92644628 0.88677686 0.87603306] [0.9306]\n",
      "[Epoch 8/100  ][Batch 132]\tLoss: 0.4813\tAccuracy: [0.99022556 0.96992481 0.92706767 0.89172932 0.87518797] [0.9308]\n",
      "[Epoch 8/100  ][Batch 144]\tLoss: 1.7662\tAccuracy: [0.99034483 0.96758621 0.92206897 0.89310345 0.86758621] [0.9281]\n",
      "[Epoch 8/100  ][Batch 156]\tLoss: 0.7864\tAccuracy: [0.98980892 0.96751592 0.92292994 0.89235669 0.86751592] [0.9280]\n",
      "[Epoch 8/100  ][Batch 168]\tLoss: 1.0663\tAccuracy: [0.98994083 0.96568047 0.92248521 0.89289941 0.86804734] [0.9278]\n",
      "[Epoch 8/100  ][Batch 180]\tLoss: 2.3816\tAccuracy: [0.99060773 0.9640884  0.92320442 0.89116022 0.86519337] [0.9269]\n",
      "[Epoch 8/100  ][Batch 192]\tLoss: 1.1034\tAccuracy: [0.99119171 0.96528497 0.92227979 0.88860104 0.86165803] [0.9258]\n",
      "[Epoch 9/100  ][Batch 12 ]\tLoss: 1.5103\tAccuracy: [0.97692308 0.96923077 0.86923077 0.85384615 0.81538462] [0.8969]\n",
      "[Epoch 9/100  ][Batch 24 ]\tLoss: 0.8224\tAccuracy: [0.988 0.976 0.9   0.884 0.824] [0.9144]\n",
      "[Epoch 9/100  ][Batch 36 ]\tLoss: 1.0261\tAccuracy: [0.98648649 0.97027027 0.91351351 0.89189189 0.82432432] [0.9173]\n",
      "[Epoch 9/100  ][Batch 48 ]\tLoss: 1.2484\tAccuracy: [0.9877551  0.96938776 0.91836735 0.88367347 0.82040816] [0.9159]\n",
      "[Epoch 9/100  ][Batch 60 ]\tLoss: 0.8377\tAccuracy: [0.98852459 0.96229508 0.92131148 0.89180328 0.83770492] [0.9203]\n",
      "[Epoch 9/100  ][Batch 72 ]\tLoss: 1.0978\tAccuracy: [0.9890411  0.96438356 0.91917808 0.88356164 0.84794521] [0.9208]\n",
      "[Epoch 9/100  ][Batch 84 ]\tLoss: 0.8243\tAccuracy: [0.98941176 0.96705882 0.92117647 0.88588235 0.85411765] [0.9235]\n",
      "[Epoch 9/100  ][Batch 96 ]\tLoss: 0.2881\tAccuracy: [0.98969072 0.96494845 0.91340206 0.88350515 0.86185567] [0.9227]\n",
      "[Epoch 9/100  ][Batch 108]\tLoss: 0.7675\tAccuracy: [0.98990826 0.96697248 0.91192661 0.88990826 0.86238532] [0.9242]\n",
      "[Epoch 9/100  ][Batch 120]\tLoss: 1.6359\tAccuracy: [0.98842975 0.9661157  0.9107438  0.89090909 0.86446281] [0.9241]\n",
      "[Epoch 9/100  ][Batch 132]\tLoss: 1.5282\tAccuracy: [0.98947368 0.96766917 0.91503759 0.8962406  0.8556391 ] [0.9248]\n",
      "[Epoch 9/100  ][Batch 144]\tLoss: 1.7841\tAccuracy: [0.98896552 0.9662069  0.91793103 0.89931034 0.84482759] [0.9234]\n",
      "[Epoch 9/100  ][Batch 156]\tLoss: 1.0234\tAccuracy: [0.98980892 0.96496815 0.91910828 0.89936306 0.83821656] [0.9223]\n",
      "[Epoch 9/100  ][Batch 168]\tLoss: 1.2146\tAccuracy: [0.9887574  0.96390533 0.92071006 0.89822485 0.83786982] [0.9219]\n",
      "[Epoch 9/100  ][Batch 180]\tLoss: 1.0620\tAccuracy: [0.98895028 0.96574586 0.92099448 0.89502762 0.84143646] [0.9224]\n",
      "[Epoch 9/100  ][Batch 192]\tLoss: 0.9656\tAccuracy: [0.98963731 0.96683938 0.92020725 0.89585492 0.84455959] [0.9234]\n",
      "[Epoch 10/100 ][Batch 12 ]\tLoss: 0.4718\tAccuracy: [0.99230769 0.97692308 0.93846154 0.93076923 0.8       ] [0.9277]\n",
      "[Epoch 10/100 ][Batch 24 ]\tLoss: 0.9155\tAccuracy: [0.996 0.972 0.924 0.904 0.832] [0.9256]\n",
      "[Epoch 10/100 ][Batch 36 ]\tLoss: 0.8656\tAccuracy: [0.99459459 0.96216216 0.93513514 0.88378378 0.84324324] [0.9238]\n",
      "[Epoch 10/100 ][Batch 48 ]\tLoss: 0.7325\tAccuracy: [0.99591837 0.96530612 0.93061224 0.88367347 0.84693878] [0.9245]\n",
      "[Epoch 10/100 ][Batch 60 ]\tLoss: 0.8420\tAccuracy: [0.99672131 0.96721311 0.9295082  0.88196721 0.86065574] [0.9272]\n",
      "[Epoch 10/100 ][Batch 72 ]\tLoss: 0.6658\tAccuracy: [0.99589041 0.96849315 0.93424658 0.89041096 0.86712329] [0.9312]\n",
      "[Epoch 10/100 ][Batch 84 ]\tLoss: 0.5755\tAccuracy: [0.99529412 0.96941176 0.92705882 0.89529412 0.86823529] [0.9311]\n",
      "[Epoch 10/100 ][Batch 96 ]\tLoss: 0.8764\tAccuracy: [0.99381443 0.96804124 0.9257732  0.89381443 0.86494845] [0.9293]\n",
      "[Epoch 10/100 ][Batch 108]\tLoss: 1.1916\tAccuracy: [0.99266055 0.96788991 0.92752294 0.89908257 0.8587156 ] [0.9292]\n",
      "[Epoch 10/100 ][Batch 120]\tLoss: 0.8500\tAccuracy: [0.99338843 0.9677686  0.92809917 0.89669421 0.85702479] [0.9286]\n",
      "[Epoch 10/100 ][Batch 132]\tLoss: 1.7044\tAccuracy: [0.9924812  0.96917293 0.92406015 0.89473684 0.85789474] [0.9277]\n",
      "[Epoch 10/100 ][Batch 144]\tLoss: 0.8704\tAccuracy: [0.99310345 0.96896552 0.91724138 0.89310345 0.86275862] [0.9270]\n",
      "[Epoch 10/100 ][Batch 156]\tLoss: 0.8329\tAccuracy: [0.99363057 0.96815287 0.91592357 0.89426752 0.86178344] [0.9268]\n",
      "[Epoch 10/100 ][Batch 168]\tLoss: 0.9991\tAccuracy: [0.99349112 0.96745562 0.91301775 0.8964497  0.86213018] [0.9265]\n",
      "[Epoch 10/100 ][Batch 180]\tLoss: 0.5274\tAccuracy: [0.99337017 0.96629834 0.91104972 0.89392265 0.86298343] [0.9255]\n",
      "[Epoch 10/100 ][Batch 192]\tLoss: 0.7371\tAccuracy: [0.99378238 0.96683938 0.91139896 0.89533679 0.8611399 ] [0.9257]\n",
      "[Epoch 11/100 ][Batch 12 ]\tLoss: 1.0031\tAccuracy: [0.99230769 0.95384615 0.91538462 0.88461538 0.84615385] [0.9185]\n",
      "[Epoch 11/100 ][Batch 24 ]\tLoss: 1.4042\tAccuracy: [0.996 0.968 0.932 0.884 0.868] [0.9296]\n",
      "[Epoch 11/100 ][Batch 36 ]\tLoss: 0.9299\tAccuracy: [0.99459459 0.97297297 0.93783784 0.88108108 0.88108108] [0.9335]\n",
      "[Epoch 11/100 ][Batch 48 ]\tLoss: 0.7258\tAccuracy: [0.99591837 0.97142857 0.93877551 0.8877551  0.88979592] [0.9367]\n",
      "[Epoch 11/100 ][Batch 60 ]\tLoss: 0.6519\tAccuracy: [0.99344262 0.97213115 0.94098361 0.89672131 0.89016393] [0.9387]\n",
      "[Epoch 11/100 ][Batch 72 ]\tLoss: 0.3663\tAccuracy: [0.99315068 0.97534247 0.94246575 0.9        0.89315068] [0.9408]\n",
      "[Epoch 11/100 ][Batch 84 ]\tLoss: 0.9477\tAccuracy: [0.99411765 0.97411765 0.94823529 0.90235294 0.89411765] [0.9426]\n",
      "[Epoch 11/100 ][Batch 96 ]\tLoss: 0.8578\tAccuracy: [0.99484536 0.97319588 0.94742268 0.90515464 0.9       ] [0.9441]\n",
      "[Epoch 11/100 ][Batch 108]\tLoss: 0.9314\tAccuracy: [0.99541284 0.97431193 0.94678899 0.90825688 0.89266055] [0.9435]\n",
      "[Epoch 11/100 ][Batch 120]\tLoss: 0.8319\tAccuracy: [0.99504132 0.97520661 0.93966942 0.90991736 0.89173554] [0.9423]\n",
      "[Epoch 11/100 ][Batch 132]\tLoss: 1.4045\tAccuracy: [0.99473684 0.97443609 0.93834586 0.90977444 0.88571429] [0.9406]\n",
      "[Epoch 11/100 ][Batch 144]\tLoss: 1.4657\tAccuracy: [0.99517241 0.9737931  0.93931034 0.90827586 0.88551724] [0.9404]\n",
      "[Epoch 11/100 ][Batch 156]\tLoss: 1.0254\tAccuracy: [0.9955414  0.97197452 0.93821656 0.91019108 0.88471338] [0.9401]\n",
      "[Epoch 11/100 ][Batch 168]\tLoss: 0.8177\tAccuracy: [0.99408284 0.97159763 0.93846154 0.91242604 0.8852071 ] [0.9404]\n",
      "[Epoch 11/100 ][Batch 180]\tLoss: 1.7950\tAccuracy: [0.99447514 0.97237569 0.93701657 0.91104972 0.88618785] [0.9402]\n",
      "[Epoch 11/100 ][Batch 192]\tLoss: 0.9207\tAccuracy: [0.99481865 0.97253886 0.93212435 0.91139896 0.88341969] [0.9389]\n",
      "[Epoch 12/100 ][Batch 12 ]\tLoss: 0.9575\tAccuracy: [0.99230769 0.96923077 0.89230769 0.88461538 0.83846154] [0.9154]\n",
      "[Epoch 12/100 ][Batch 24 ]\tLoss: 0.9400\tAccuracy: [0.988 0.96  0.896 0.9   0.816] [0.9120]\n",
      "[Epoch 12/100 ][Batch 36 ]\tLoss: 0.7119\tAccuracy: [0.99189189 0.96486486 0.9        0.90540541 0.84324324] [0.9211]\n",
      "[Epoch 12/100 ][Batch 48 ]\tLoss: 0.3568\tAccuracy: [0.99183673 0.96938776 0.91020408 0.91020408 0.86326531] [0.9290]\n",
      "[Epoch 12/100 ][Batch 60 ]\tLoss: 0.4355\tAccuracy: [0.99180328 0.97213115 0.91967213 0.91639344 0.87213115] [0.9344]\n",
      "[Epoch 12/100 ][Batch 72 ]\tLoss: 0.7818\tAccuracy: [0.99315068 0.97534247 0.9260274  0.91780822 0.88219178] [0.9389]\n",
      "[Epoch 12/100 ][Batch 84 ]\tLoss: 1.0110\tAccuracy: [0.99294118 0.97411765 0.92823529 0.92352941 0.88705882] [0.9412]\n",
      "[Epoch 12/100 ][Batch 96 ]\tLoss: 0.9089\tAccuracy: [0.99278351 0.97319588 0.9257732  0.92680412 0.88969072] [0.9416]\n",
      "[Epoch 12/100 ][Batch 108]\tLoss: 0.5120\tAccuracy: [0.99357798 0.9733945  0.92752294 0.92385321 0.88715596] [0.9411]\n",
      "[Epoch 12/100 ][Batch 120]\tLoss: 0.7074\tAccuracy: [0.99338843 0.97190083 0.92479339 0.9231405  0.88842975] [0.9403]\n",
      "[Epoch 12/100 ][Batch 132]\tLoss: 3.5971\tAccuracy: [0.99323308 0.97368421 0.92481203 0.92330827 0.88571429] [0.9402]\n",
      "[Epoch 12/100 ][Batch 144]\tLoss: 0.8679\tAccuracy: [0.99310345 0.97310345 0.92896552 0.92275862 0.88896552] [0.9414]\n",
      "[Epoch 12/100 ][Batch 156]\tLoss: 0.2564\tAccuracy: [0.99363057 0.97388535 0.92929936 0.92356688 0.89044586] [0.9422]\n",
      "[Epoch 12/100 ][Batch 168]\tLoss: 0.7107\tAccuracy: [0.99408284 0.97455621 0.9260355  0.91952663 0.89171598] [0.9412]\n",
      "[Epoch 12/100 ][Batch 180]\tLoss: 1.0000\tAccuracy: [0.99447514 0.97348066 0.92651934 0.91712707 0.88839779] [0.9400]\n",
      "[Epoch 12/100 ][Batch 192]\tLoss: 0.9252\tAccuracy: [0.99430052 0.97098446 0.92227979 0.91243523 0.88549223] [0.9371]\n",
      "[Epoch 13/100 ][Batch 12 ]\tLoss: 0.9671\tAccuracy: [0.98461538 0.99230769 0.90769231 0.87692308 0.79230769] [0.9108]\n",
      "[Epoch 13/100 ][Batch 24 ]\tLoss: 1.8825\tAccuracy: [0.988 0.98  0.904 0.868 0.804] [0.9088]\n",
      "[Epoch 13/100 ][Batch 36 ]\tLoss: 0.9756\tAccuracy: [0.98918919 0.98378378 0.90810811 0.87837838 0.77297297] [0.9065]\n",
      "[Epoch 13/100 ][Batch 48 ]\tLoss: 0.2832\tAccuracy: [0.98979592 0.98571429 0.91020408 0.89591837 0.80204082] [0.9167]\n",
      "[Epoch 13/100 ][Batch 60 ]\tLoss: 0.5380\tAccuracy: [0.99180328 0.98360656 0.90327869 0.90163934 0.82622951] [0.9213]\n",
      "[Epoch 13/100 ][Batch 72 ]\tLoss: 1.0419\tAccuracy: [0.99315068 0.98356164 0.91369863 0.90136986 0.84246575] [0.9268]\n",
      "[Epoch 13/100 ][Batch 84 ]\tLoss: 0.4903\tAccuracy: [0.99411765 0.98470588 0.92588235 0.90823529 0.85411765] [0.9334]\n",
      "[Epoch 13/100 ][Batch 96 ]\tLoss: 0.6623\tAccuracy: [0.99484536 0.98350515 0.92474227 0.91340206 0.85979381] [0.9353]\n",
      "[Epoch 13/100 ][Batch 108]\tLoss: 1.4042\tAccuracy: [0.99541284 0.98256881 0.93027523 0.91009174 0.84954128] [0.9336]\n",
      "[Epoch 13/100 ][Batch 120]\tLoss: 1.1720\tAccuracy: [0.99504132 0.98099174 0.93057851 0.91157025 0.84380165] [0.9324]\n",
      "[Epoch 13/100 ][Batch 132]\tLoss: 1.1013\tAccuracy: [0.99473684 0.98045113 0.93157895 0.90977444 0.82857143] [0.9290]\n",
      "[Epoch 13/100 ][Batch 144]\tLoss: 1.4093\tAccuracy: [0.99517241 0.97931034 0.9337931  0.90896552 0.81103448] [0.9257]\n",
      "[Epoch 13/100 ][Batch 156]\tLoss: 1.2551\tAccuracy: [0.9955414  0.97834395 0.93375796 0.90955414 0.80382166] [0.9242]\n",
      "[Epoch 13/100 ][Batch 168]\tLoss: 1.3799\tAccuracy: [0.99526627 0.97633136 0.93372781 0.90828402 0.80177515] [0.9231]\n",
      "[Epoch 13/100 ][Batch 180]\tLoss: 0.7813\tAccuracy: [0.99447514 0.97624309 0.93314917 0.90994475 0.80276243] [0.9233]\n",
      "[Epoch 13/100 ][Batch 192]\tLoss: 0.5916\tAccuracy: [0.99378238 0.97772021 0.93056995 0.91088083 0.80725389] [0.9240]\n",
      "[Epoch 14/100 ][Batch 12 ]\tLoss: 1.0575\tAccuracy: [0.99230769 0.99230769 0.96153846 0.86923077 0.87692308] [0.9385]\n",
      "[Epoch 14/100 ][Batch 24 ]\tLoss: 1.4159\tAccuracy: [0.996 0.968 0.944 0.848 0.856] [0.9224]\n",
      "[Epoch 14/100 ][Batch 36 ]\tLoss: 0.5559\tAccuracy: [0.9972973  0.97297297 0.93783784 0.85405405 0.84054054] [0.9205]\n",
      "[Epoch 14/100 ][Batch 48 ]\tLoss: 0.9919\tAccuracy: [0.99795918 0.97755102 0.93061224 0.85714286 0.83265306] [0.9192]\n",
      "[Epoch 14/100 ][Batch 60 ]\tLoss: 0.5055\tAccuracy: [0.99344262 0.97213115 0.9295082  0.86885246 0.85081967] [0.9230]\n",
      "[Epoch 14/100 ][Batch 72 ]\tLoss: 1.1906\tAccuracy: [0.99315068 0.9739726  0.93013699 0.87945205 0.85342466] [0.9260]\n",
      "[Epoch 14/100 ][Batch 84 ]\tLoss: 0.6199\tAccuracy: [0.99411765 0.97647059 0.93529412 0.88       0.86117647] [0.9294]\n",
      "[Epoch 14/100 ][Batch 96 ]\tLoss: 0.7859\tAccuracy: [0.99484536 0.97628866 0.93608247 0.88969072 0.86701031] [0.9328]\n",
      "[Epoch 14/100 ][Batch 108]\tLoss: 0.8166\tAccuracy: [0.99357798 0.97522936 0.93761468 0.89082569 0.8733945 ] [0.9341]\n",
      "[Epoch 14/100 ][Batch 120]\tLoss: 0.8090\tAccuracy: [0.99338843 0.97520661 0.93801653 0.89338843 0.87603306] [0.9352]\n",
      "[Epoch 14/100 ][Batch 132]\tLoss: 0.9206\tAccuracy: [0.99398496 0.97593985 0.93684211 0.89398496 0.87894737] [0.9359]\n",
      "[Epoch 14/100 ][Batch 144]\tLoss: 0.8909\tAccuracy: [0.9937931  0.97655172 0.93517241 0.89310345 0.87862069] [0.9354]\n",
      "[Epoch 14/100 ][Batch 156]\tLoss: 0.7943\tAccuracy: [0.99299363 0.97515924 0.93248408 0.89044586 0.87961783] [0.9341]\n",
      "[Epoch 14/100 ][Batch 168]\tLoss: 0.8301\tAccuracy: [0.99349112 0.97514793 0.93254438 0.89112426 0.88106509] [0.9347]\n",
      "[Epoch 14/100 ][Batch 180]\tLoss: 1.1347\tAccuracy: [0.99226519 0.97237569 0.93314917 0.89116022 0.8801105 ] [0.9338]\n",
      "[Epoch 14/100 ][Batch 192]\tLoss: 0.7047\tAccuracy: [0.99274611 0.97253886 0.93212435 0.88911917 0.88186528] [0.9337]\n",
      "[Epoch 15/100 ][Batch 12 ]\tLoss: 0.6268\tAccuracy: [1.         0.97692308 0.89230769 0.84615385 0.88461538] [0.9200]\n",
      "[Epoch 15/100 ][Batch 24 ]\tLoss: 0.9181\tAccuracy: [1.    0.964 0.912 0.844 0.892] [0.9224]\n",
      "[Epoch 15/100 ][Batch 36 ]\tLoss: 0.6534\tAccuracy: [0.9972973  0.97027027 0.92162162 0.85405405 0.9       ] [0.9286]\n",
      "[Epoch 15/100 ][Batch 48 ]\tLoss: 0.3022\tAccuracy: [0.99591837 0.96938776 0.92040816 0.85306122 0.90816327] [0.9294]\n",
      "[Epoch 15/100 ][Batch 60 ]\tLoss: 0.4106\tAccuracy: [0.99672131 0.97213115 0.9295082  0.87377049 0.90327869] [0.9351]\n",
      "[Epoch 15/100 ][Batch 72 ]\tLoss: 0.6855\tAccuracy: [0.99726027 0.97123288 0.93150685 0.88356164 0.89726027] [0.9362]\n",
      "[Epoch 15/100 ][Batch 84 ]\tLoss: 0.4874\tAccuracy: [0.99764706 0.97411765 0.93882353 0.88705882 0.90352941] [0.9402]\n",
      "[Epoch 15/100 ][Batch 96 ]\tLoss: 1.4070\tAccuracy: [0.99587629 0.97319588 0.94329897 0.8814433  0.90824742] [0.9404]\n",
      "[Epoch 15/100 ][Batch 108]\tLoss: 0.8342\tAccuracy: [0.99541284 0.97522936 0.94587156 0.87247706 0.91192661] [0.9402]\n",
      "[Epoch 15/100 ][Batch 120]\tLoss: 0.9456\tAccuracy: [0.99586777 0.9768595  0.94297521 0.8661157  0.91570248] [0.9395]\n",
      "[Epoch 15/100 ][Batch 132]\tLoss: 1.0379\tAccuracy: [0.99548872 0.97593985 0.9406015  0.86390977 0.91503759] [0.9382]\n",
      "[Epoch 15/100 ][Batch 144]\tLoss: 0.8586\tAccuracy: [0.99586207 0.97793103 0.93724138 0.86482759 0.91793103] [0.9388]\n",
      "[Epoch 15/100 ][Batch 156]\tLoss: 1.3100\tAccuracy: [0.99617834 0.97770701 0.9343949  0.87133758 0.91910828] [0.9397]\n",
      "[Epoch 15/100 ][Batch 168]\tLoss: 0.7835\tAccuracy: [0.99585799 0.97928994 0.93491124 0.87573964 0.92071006] [0.9413]\n",
      "[Epoch 15/100 ][Batch 180]\tLoss: 0.8821\tAccuracy: [0.9961326  0.9801105  0.93425414 0.87845304 0.9198895 ] [0.9418]\n",
      "[Epoch 15/100 ][Batch 192]\tLoss: 0.4415\tAccuracy: [0.99637306 0.97927461 0.93523316 0.87979275 0.92176166] [0.9425]\n",
      "[Epoch 16/100 ][Batch 12 ]\tLoss: 0.6951\tAccuracy: [0.99230769 0.96153846 0.94615385 0.9        0.96153846] [0.9523]\n",
      "[Epoch 16/100 ][Batch 24 ]\tLoss: 0.8678\tAccuracy: [0.992 0.964 0.944 0.908 0.948] [0.9512]\n",
      "[Epoch 16/100 ][Batch 36 ]\tLoss: 0.9944\tAccuracy: [0.99189189 0.96486486 0.93783784 0.88918919 0.95135135] [0.9470]\n",
      "[Epoch 16/100 ][Batch 48 ]\tLoss: 1.0238\tAccuracy: [0.99183673 0.96734694 0.93469388 0.87755102 0.94285714] [0.9429]\n",
      "[Epoch 16/100 ][Batch 60 ]\tLoss: 0.4277\tAccuracy: [0.99344262 0.9704918  0.93606557 0.88360656 0.94262295] [0.9452]\n",
      "[Epoch 16/100 ][Batch 72 ]\tLoss: 0.4271\tAccuracy: [0.99315068 0.97123288 0.93972603 0.88630137 0.93835616] [0.9458]\n",
      "[Epoch 16/100 ][Batch 84 ]\tLoss: 0.5483\tAccuracy: [0.99411765 0.97529412 0.94470588 0.89058824 0.93882353] [0.9487]\n",
      "[Epoch 16/100 ][Batch 96 ]\tLoss: 0.8064\tAccuracy: [0.99484536 0.97628866 0.94639175 0.9        0.94226804] [0.9520]\n",
      "[Epoch 16/100 ][Batch 108]\tLoss: 1.0861\tAccuracy: [0.99541284 0.97522936 0.94678899 0.90183486 0.93853211] [0.9516]\n",
      "[Epoch 16/100 ][Batch 120]\tLoss: 1.1684\tAccuracy: [0.99586777 0.97603306 0.94545455 0.89752066 0.9338843 ] [0.9498]\n",
      "[Epoch 16/100 ][Batch 132]\tLoss: 1.1356\tAccuracy: [0.9962406  0.97593985 0.9481203  0.88721805 0.93233083] [0.9480]\n",
      "[Epoch 16/100 ][Batch 144]\tLoss: 0.9051\tAccuracy: [0.99655172 0.97724138 0.94965517 0.88551724 0.92965517] [0.9477]\n",
      "[Epoch 16/100 ][Batch 156]\tLoss: 0.7890\tAccuracy: [0.99681529 0.97770701 0.94968153 0.88343949 0.93121019] [0.9478]\n",
      "[Epoch 16/100 ][Batch 168]\tLoss: 0.8017\tAccuracy: [0.99704142 0.97692308 0.95147929 0.87692308 0.93136095] [0.9467]\n",
      "[Epoch 16/100 ][Batch 180]\tLoss: 0.6212\tAccuracy: [0.99668508 0.97790055 0.95248619 0.87845304 0.93093923] [0.9473]\n",
      "[Epoch 16/100 ][Batch 192]\tLoss: 1.6110\tAccuracy: [0.99689119 0.97875648 0.95284974 0.88186528 0.93212435] [0.9485]\n",
      "[Epoch 17/100 ][Batch 12 ]\tLoss: 0.8171\tAccuracy: [1.         0.97692308 0.97692308 0.93076923 0.95384615] [0.9677]\n",
      "[Epoch 17/100 ][Batch 24 ]\tLoss: 0.1142\tAccuracy: [0.996 0.972 0.976 0.924 0.928] [0.9592]\n",
      "[Epoch 17/100 ][Batch 36 ]\tLoss: 0.4477\tAccuracy: [0.9972973  0.98108108 0.97297297 0.92432432 0.94054054] [0.9632]\n",
      "[Epoch 17/100 ][Batch 48 ]\tLoss: 0.5370\tAccuracy: [0.99795918 0.98163265 0.97142857 0.93061224 0.94285714] [0.9649]\n",
      "[Epoch 17/100 ][Batch 60 ]\tLoss: 0.5926\tAccuracy: [0.99672131 0.9852459  0.96721311 0.92786885 0.93770492] [0.9630]\n",
      "[Epoch 17/100 ][Batch 72 ]\tLoss: 0.6936\tAccuracy: [0.99589041 0.98493151 0.96712329 0.92465753 0.9369863 ] [0.9619]\n",
      "[Epoch 17/100 ][Batch 84 ]\tLoss: 0.8007\tAccuracy: [0.99647059 0.98588235 0.96235294 0.93058824 0.93764706] [0.9626]\n",
      "[Epoch 17/100 ][Batch 96 ]\tLoss: 0.3308\tAccuracy: [0.99690722 0.98453608 0.96185567 0.9371134  0.94123711] [0.9643]\n",
      "[Epoch 17/100 ][Batch 108]\tLoss: 0.9888\tAccuracy: [0.99724771 0.98348624 0.96330275 0.93761468 0.94495413] [0.9653]\n",
      "[Epoch 17/100 ][Batch 120]\tLoss: 0.5551\tAccuracy: [0.99752066 0.98347107 0.96198347 0.93636364 0.94710744] [0.9653]\n",
      "[Epoch 17/100 ][Batch 132]\tLoss: 0.5668\tAccuracy: [0.99774436 0.98496241 0.96240602 0.93684211 0.94962406] [0.9663]\n",
      "[Epoch 17/100 ][Batch 144]\tLoss: 0.3536\tAccuracy: [0.99793103 0.9862069  0.96275862 0.94       0.95103448] [0.9676]\n",
      "[Epoch 17/100 ][Batch 156]\tLoss: 0.7498\tAccuracy: [0.99745223 0.98471338 0.96050955 0.9388535  0.94713376] [0.9657]\n",
      "[Epoch 17/100 ][Batch 168]\tLoss: 0.5870\tAccuracy: [0.99704142 0.98106509 0.96035503 0.93727811 0.9443787 ] [0.9640]\n",
      "[Epoch 17/100 ][Batch 180]\tLoss: 0.0810\tAccuracy: [0.99558011 0.97900552 0.96022099 0.93701657 0.94254144] [0.9629]\n",
      "[Epoch 17/100 ][Batch 192]\tLoss: 1.2455\tAccuracy: [0.99585492 0.97823834 0.96010363 0.93782383 0.94041451] [0.9625]\n",
      "[Epoch 18/100 ][Batch 12 ]\tLoss: 0.4732\tAccuracy: [0.99230769 0.98461538 0.96923077 0.93076923 0.93076923] [0.9615]\n",
      "[Epoch 18/100 ][Batch 24 ]\tLoss: 0.3651\tAccuracy: [0.996 0.976 0.976 0.944 0.92 ] [0.9624]\n",
      "[Epoch 18/100 ][Batch 36 ]\tLoss: 0.6912\tAccuracy: [0.99459459 0.97567568 0.97567568 0.94594595 0.92972973] [0.9643]\n",
      "[Epoch 18/100 ][Batch 48 ]\tLoss: 0.2649\tAccuracy: [0.99183673 0.97755102 0.97142857 0.95102041 0.93469388] [0.9653]\n",
      "[Epoch 18/100 ][Batch 60 ]\tLoss: 0.2846\tAccuracy: [0.99180328 0.97868852 0.97540984 0.9557377  0.9442623 ] [0.9692]\n",
      "[Epoch 18/100 ][Batch 72 ]\tLoss: 0.5696\tAccuracy: [0.99315068 0.97808219 0.97534247 0.95616438 0.94657534] [0.9699]\n",
      "[Epoch 18/100 ][Batch 84 ]\tLoss: 0.1539\tAccuracy: [0.99411765 0.98       0.97411765 0.95882353 0.94470588] [0.9704]\n",
      "[Epoch 18/100 ][Batch 96 ]\tLoss: 0.1077\tAccuracy: [0.99381443 0.98041237 0.9742268  0.95773196 0.94742268] [0.9707]\n",
      "[Epoch 18/100 ][Batch 108]\tLoss: 0.4005\tAccuracy: [0.99449541 0.98073394 0.97614679 0.9587156  0.95137615] [0.9723]\n",
      "[Epoch 18/100 ][Batch 120]\tLoss: 0.6112\tAccuracy: [0.99504132 0.98181818 0.9768595  0.96033058 0.95206612] [0.9732]\n",
      "[Epoch 18/100 ][Batch 132]\tLoss: 0.5971\tAccuracy: [0.99548872 0.98270677 0.97744361 0.95789474 0.95338346] [0.9734]\n",
      "[Epoch 18/100 ][Batch 144]\tLoss: 0.4917\tAccuracy: [0.99586207 0.98206897 0.97517241 0.95793103 0.95310345] [0.9728]\n",
      "[Epoch 18/100 ][Batch 156]\tLoss: 0.6214\tAccuracy: [0.99617834 0.98343949 0.97388535 0.95859873 0.95414013] [0.9732]\n",
      "[Epoch 18/100 ][Batch 168]\tLoss: 0.6045\tAccuracy: [0.9964497  0.98402367 0.97573964 0.9591716  0.95325444] [0.9737]\n",
      "[Epoch 18/100 ][Batch 180]\tLoss: 0.4208\tAccuracy: [0.99668508 0.98453039 0.97403315 0.95801105 0.95138122] [0.9729]\n",
      "[Epoch 18/100 ][Batch 192]\tLoss: 0.5461\tAccuracy: [0.99689119 0.98393782 0.97305699 0.95336788 0.94974093] [0.9714]\n",
      "[Epoch 19/100 ][Batch 12 ]\tLoss: 0.1406\tAccuracy: [1.         0.99230769 0.96923077 0.97692308 0.95384615] [0.9785]\n",
      "[Epoch 19/100 ][Batch 24 ]\tLoss: 0.6226\tAccuracy: [0.996 0.988 0.964 0.948 0.94 ] [0.9672]\n",
      "[Epoch 19/100 ][Batch 36 ]\tLoss: 0.7483\tAccuracy: [0.9972973  0.98378378 0.95945946 0.94594595 0.94324324] [0.9659]\n",
      "[Epoch 19/100 ][Batch 48 ]\tLoss: 0.6281\tAccuracy: [0.99795918 0.98367347 0.96326531 0.94693878 0.94285714] [0.9669]\n",
      "[Epoch 19/100 ][Batch 60 ]\tLoss: 1.0585\tAccuracy: [0.99672131 0.9852459  0.96393443 0.94918033 0.94098361] [0.9672]\n",
      "[Epoch 19/100 ][Batch 72 ]\tLoss: 0.4230\tAccuracy: [0.99726027 0.98630137 0.96712329 0.95342466 0.94383562] [0.9696]\n",
      "[Epoch 19/100 ][Batch 84 ]\tLoss: 0.2338\tAccuracy: [0.99764706 0.98470588 0.96823529 0.95529412 0.94705882] [0.9706]\n",
      "[Epoch 19/100 ][Batch 96 ]\tLoss: 0.1483\tAccuracy: [0.99793814 0.98453608 0.97010309 0.95876289 0.95051546] [0.9724]\n",
      "[Epoch 19/100 ][Batch 108]\tLoss: 0.5551\tAccuracy: [0.99816514 0.9853211  0.9706422  0.95779817 0.95229358] [0.9728]\n",
      "[Epoch 19/100 ][Batch 120]\tLoss: 0.4099\tAccuracy: [0.99752066 0.98595041 0.97190083 0.95702479 0.95289256] [0.9731]\n",
      "[Epoch 19/100 ][Batch 132]\tLoss: 1.1629\tAccuracy: [0.9962406  0.98270677 0.97293233 0.95413534 0.9518797 ] [0.9716]\n",
      "[Epoch 19/100 ][Batch 144]\tLoss: 0.4333\tAccuracy: [0.99448276 0.97931034 0.97310345 0.95448276 0.94965517] [0.9702]\n",
      "[Epoch 19/100 ][Batch 156]\tLoss: 0.5276\tAccuracy: [0.99299363 0.98089172 0.97133758 0.95477707 0.95031847] [0.9701]\n",
      "[Epoch 19/100 ][Batch 168]\tLoss: 0.7126\tAccuracy: [0.99349112 0.98106509 0.97278107 0.95443787 0.95088757] [0.9705]\n",
      "[Epoch 19/100 ][Batch 180]\tLoss: 0.3677\tAccuracy: [0.99337017 0.98232044 0.97458564 0.95524862 0.95027624] [0.9712]\n",
      "[Epoch 19/100 ][Batch 192]\tLoss: 0.5230\tAccuracy: [0.99378238 0.98031088 0.97253886 0.95595855 0.95181347] [0.9709]\n",
      "[Epoch 20/100 ][Batch 12 ]\tLoss: 0.1836\tAccuracy: [0.91538462 0.96923077 0.96923077 0.96923077 0.92307692] [0.9492]\n",
      "[Epoch 20/100 ][Batch 24 ]\tLoss: 0.5572\tAccuracy: [0.944 0.972 0.976 0.968 0.92 ] [0.9560]\n",
      "[Epoch 20/100 ][Batch 36 ]\tLoss: 0.1183\tAccuracy: [0.95945946 0.96756757 0.98108108 0.96486486 0.93513514] [0.9616]\n",
      "[Epoch 20/100 ][Batch 48 ]\tLoss: 0.2937\tAccuracy: [0.96938776 0.97142857 0.98367347 0.96530612 0.94081633] [0.9661]\n",
      "[Epoch 20/100 ][Batch 60 ]\tLoss: 0.8248\tAccuracy: [0.97540984 0.97377049 0.98196721 0.96229508 0.9442623 ] [0.9675]\n",
      "[Epoch 20/100 ][Batch 72 ]\tLoss: 0.2404\tAccuracy: [0.97945205 0.97534247 0.98219178 0.9630137  0.94657534] [0.9693]\n",
      "[Epoch 20/100 ][Batch 84 ]\tLoss: 0.8871\tAccuracy: [0.98235294 0.97647059 0.98       0.96470588 0.94823529] [0.9704]\n",
      "[Epoch 20/100 ][Batch 96 ]\tLoss: 0.2808\tAccuracy: [0.98350515 0.97525773 0.97525773 0.96391753 0.94948454] [0.9695]\n",
      "[Epoch 20/100 ][Batch 108]\tLoss: 0.2316\tAccuracy: [0.9853211  0.97614679 0.97522936 0.96422018 0.94770642] [0.9697]\n",
      "[Epoch 20/100 ][Batch 120]\tLoss: 0.2829\tAccuracy: [0.98677686 0.97768595 0.97768595 0.96033058 0.94876033] [0.9702]\n",
      "[Epoch 20/100 ][Batch 132]\tLoss: 0.7301\tAccuracy: [0.98721805 0.97669173 0.97819549 0.9593985  0.94736842] [0.9698]\n",
      "[Epoch 20/100 ][Batch 144]\tLoss: 0.3493\tAccuracy: [0.98758621 0.97862069 0.97862069 0.96137931 0.94896552] [0.9710]\n",
      "[Epoch 20/100 ][Batch 156]\tLoss: 0.7281\tAccuracy: [0.98853503 0.98025478 0.97961783 0.95859873 0.95031847] [0.9715]\n",
      "[Epoch 20/100 ][Batch 168]\tLoss: 0.4677\tAccuracy: [0.98757396 0.98106509 0.97810651 0.95680473 0.95147929] [0.9710]\n",
      "[Epoch 20/100 ][Batch 180]\tLoss: 0.3815\tAccuracy: [0.98674033 0.98232044 0.97900552 0.95690608 0.9519337 ] [0.9714]\n",
      "[Epoch 20/100 ][Batch 192]\tLoss: 0.3008\tAccuracy: [0.98704663 0.98186528 0.97927461 0.95803109 0.95336788] [0.9719]\n",
      "[Epoch 21/100 ][Batch 12 ]\tLoss: 1.3647\tAccuracy: [1.         0.99230769 0.96153846 0.97692308 0.90769231] [0.9677]\n",
      "[Epoch 21/100 ][Batch 24 ]\tLoss: 0.6913\tAccuracy: [0.996 0.98  0.944 0.948 0.932] [0.9600]\n",
      "[Epoch 21/100 ][Batch 36 ]\tLoss: 0.4174\tAccuracy: [0.9972973  0.98378378 0.94864865 0.95135135 0.93243243] [0.9627]\n",
      "[Epoch 21/100 ][Batch 48 ]\tLoss: 0.3683\tAccuracy: [0.99795918 0.98163265 0.95102041 0.94693878 0.93877551] [0.9633]\n",
      "[Epoch 21/100 ][Batch 60 ]\tLoss: 0.3098\tAccuracy: [0.99672131 0.98360656 0.9557377  0.94754098 0.94098361] [0.9649]\n",
      "[Epoch 21/100 ][Batch 72 ]\tLoss: 0.9329\tAccuracy: [0.99726027 0.97945205 0.95753425 0.94931507 0.94246575] [0.9652]\n",
      "[Epoch 21/100 ][Batch 84 ]\tLoss: 1.1034\tAccuracy: [0.99647059 0.97882353 0.96       0.95294118 0.94823529] [0.9673]\n",
      "[Epoch 21/100 ][Batch 96 ]\tLoss: 0.1910\tAccuracy: [0.99587629 0.97938144 0.9628866  0.95463918 0.94742268] [0.9680]\n",
      "[Epoch 21/100 ][Batch 108]\tLoss: 0.2905\tAccuracy: [0.99633028 0.97706422 0.96605505 0.9587156  0.94954128] [0.9695]\n",
      "[Epoch 21/100 ][Batch 120]\tLoss: 0.4340\tAccuracy: [0.99669421 0.97933884 0.96694215 0.95950413 0.94710744] [0.9699]\n",
      "[Epoch 21/100 ][Batch 132]\tLoss: 0.5372\tAccuracy: [0.9962406  0.97969925 0.96541353 0.96090226 0.94887218] [0.9702]\n",
      "[Epoch 21/100 ][Batch 144]\tLoss: 0.6181\tAccuracy: [0.99655172 0.98       0.96344828 0.96068966 0.94206897] [0.9686]\n",
      "[Epoch 21/100 ][Batch 156]\tLoss: 0.2179\tAccuracy: [0.99681529 0.97961783 0.96178344 0.96242038 0.94140127] [0.9684]\n",
      "[Epoch 21/100 ][Batch 168]\tLoss: 0.5490\tAccuracy: [0.99704142 0.97988166 0.96153846 0.96390533 0.94378698] [0.9692]\n",
      "[Epoch 21/100 ][Batch 180]\tLoss: 0.0595\tAccuracy: [0.99723757 0.98066298 0.96243094 0.96298343 0.94585635] [0.9698]\n",
      "[Epoch 21/100 ][Batch 192]\tLoss: 0.9940\tAccuracy: [0.99689119 0.98031088 0.96476684 0.9611399  0.94559585] [0.9697]\n",
      "[Epoch 22/100 ][Batch 12 ]\tLoss: 1.0224\tAccuracy: [0.99230769 0.96923077 0.93076923 0.90769231 0.88461538] [0.9369]\n",
      "[Epoch 22/100 ][Batch 24 ]\tLoss: 0.4970\tAccuracy: [0.988 0.98  0.956 0.932 0.904] [0.9520]\n",
      "[Epoch 22/100 ][Batch 36 ]\tLoss: 0.2256\tAccuracy: [0.98918919 0.98108108 0.96486486 0.93243243 0.92702703] [0.9589]\n",
      "[Epoch 22/100 ][Batch 48 ]\tLoss: 0.1377\tAccuracy: [0.99183673 0.98163265 0.96938776 0.94081633 0.93265306] [0.9633]\n",
      "[Epoch 22/100 ][Batch 60 ]\tLoss: 0.4771\tAccuracy: [0.99344262 0.98196721 0.97377049 0.95081967 0.93934426] [0.9679]\n",
      "[Epoch 22/100 ][Batch 72 ]\tLoss: 0.8355\tAccuracy: [0.99452055 0.98493151 0.97671233 0.95753425 0.93287671] [0.9693]\n",
      "[Epoch 22/100 ][Batch 84 ]\tLoss: 0.9020\tAccuracy: [0.99411765 0.98588235 0.97529412 0.96       0.91882353] [0.9668]\n",
      "[Epoch 22/100 ][Batch 96 ]\tLoss: 0.3240\tAccuracy: [0.99381443 0.98453608 0.97319588 0.95463918 0.91546392] [0.9643]\n",
      "[Epoch 22/100 ][Batch 108]\tLoss: 0.6252\tAccuracy: [0.99449541 0.98623853 0.97431193 0.95137615 0.91651376] [0.9646]\n",
      "[Epoch 22/100 ][Batch 120]\tLoss: 0.4254\tAccuracy: [0.99504132 0.98677686 0.97520661 0.95123967 0.91652893] [0.9650]\n",
      "[Epoch 22/100 ][Batch 132]\tLoss: 0.3369\tAccuracy: [0.99398496 0.98646617 0.97593985 0.95338346 0.92030075] [0.9660]\n",
      "[Epoch 22/100 ][Batch 144]\tLoss: 0.4588\tAccuracy: [0.9937931  0.98758621 0.97586207 0.95310345 0.92275862] [0.9666]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     55\u001b[0m \tloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(y_pred[:, i, :], y_train_labeled[:, i])\n\u001b[0;32m---> 57\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m opt \u001b[38;5;129;01min\u001b[39;00m optimizers:\n\u001b[1;32m     59\u001b[0m \topt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3.11/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1) Set up loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.AdamW([\n",
    "\t{'params': model.conv.parameters(), \"lr\": 0.0001},\n",
    "\t{'params': model.fc1.parameters(), \"lr\": 0.0001},\n",
    "\t{'params': model.out_v1.parameters(), \"lr\": 0.0001},\n",
    "\t{'params': model.out_v2.parameters(), \"lr\": 0.0001},\n",
    "\t{'params': model.out_v3.parameters(), \"lr\": 0.0001},\n",
    "\t{'params': model.out_v4.parameters(), \"lr\": 0.0001},\n",
    "\t{'params': model.out_v5.parameters(), \"lr\": 0.0001},\n",
    "])\n",
    "\n",
    "lr = 5e-6\n",
    "optimizers = [\n",
    "\ttorch.optim.AdamW(model.out_v1.parameters(), lr=lr),\n",
    "\ttorch.optim.AdamW(model.out_v2.parameters(), lr=lr),\n",
    "\ttorch.optim.AdamW(model.out_v3.parameters(), lr=lr),\n",
    "\ttorch.optim.AdamW(model.out_v4.parameters(), lr=lr),\n",
    "\ttorch.optim.AdamW(model.out_v5.parameters(), lr=lr),\n",
    "\ttorch.optim.AdamW([\n",
    "\t\t{'params': model.conv.parameters(), \"lr\": lr},\n",
    "\t\t{'params': model.fc1.parameters(), \"lr\": lr},\n",
    "\t]),\n",
    "]\n",
    "\n",
    "report_interval = 12\n",
    "accuracy_hist = utils.Accuracy()\n",
    "loss_hist = []\n",
    "condition = 'RNFN'\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "\toptimizer.zero_grad()\n",
    "\tfor optimizer in optimizers:\n",
    "\t\toptimizer.zero_grad()\n",
    "\n",
    "\tfor batch_idx, (X_train, y_train) in enumerate(dl):\n",
    "\t\tfor k, v in X_train.items():\n",
    "\t\t\tX_train[k] = v.to(DEVICE)\n",
    "\t\tfor k, v in y_train.items():\n",
    "\t\t\ty_train[k] = v.to(DEVICE)\n",
    "\n",
    "\t\t# 2) Forward Propagation\n",
    "\t\ty_pred = model(X_train)\n",
    "\t\t# break\n",
    "\n",
    "\t\t# 3) loss calculation\n",
    "\t\ty_train_labeled = y_train[condition].argmax(dim=2)\n",
    "\t\tloss = 0\n",
    "\t\tfor i in range(5):\n",
    "\t\t\tloss += criterion(y_pred[:, i, :], y_train_labeled[:, i])\n",
    "\t\t\t\t\n",
    "\t\tloss.backward()\n",
    "\t\tfor opt in optimizers:\n",
    "\t\t\topt.step()\n",
    "\n",
    "\t\tacc = accuracy_hist.calc_accuracy(y_pred, y_train[condition], epoch)\n",
    "\t\tloss_hist.append(loss.item())\n",
    "\n",
    "\t\tif batch_idx > 0 and batch_idx % report_interval == 0:\n",
    "\t\t\tcurr_loss = sum(loss_hist[-10:]) / report_interval\n",
    "\t\t\tprint(f\"[Epoch {f'{epoch+1}/{epochs}':<7}][Batch {batch_idx:<3}]\\tLoss: {loss:.4f}\\tAccuracy: {acc} [{acc.mean():.4f}]\")\n",
    "\t\t\ttorch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(model, f'models/{condition}-model-dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80325/3726344571.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('models/SCS-model-dict.pt').to(DEVICE)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('models/SCS-model-dict.pt').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.06666667014360428\n",
      "\n",
      "Metric = 0.06666667014360428\n",
      "\n",
      "Metric = 0.03333333507180214\n",
      "\n",
      "Metric = 0.03333333507180214\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.03333333507180214\n",
      "\n",
      "Metric = 0.03333333507180214\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.02500000037252903\n",
      "\n",
      "Metric = 0.02500000037252903\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.125\n",
      "\n",
      "Metric = 0.125\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.02500000037252903\n",
      "\n",
      "Metric = 0.02500000037252903\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.05833333358168602\n",
      "\n",
      "Metric = 0.05833333358168602\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.0416666679084301\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.02500000037252903\n",
      "\n",
      "Metric = 0.02500000037252903\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.008333333767950535\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.05000000074505806\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.01666666753590107\n",
      "\n",
      "Metric = 0.03333333507180214\n",
      "\n",
      "Metric = 0.03333333507180214\n",
      "\n",
      "Metric = 0.0\n",
      "\n",
      "Metric = 0.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train, y_train \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[1;32m      4\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m X_train\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 5\u001b[0m \t\tX_train[k] \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m y_train\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m \t\ty_train[k] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor X_train, y_train in dl:\n",
    "\t\tfor k, v in X_train.items():\n",
    "\t\t\tX_train[k] = v.to(DEVICE)\n",
    "\t\tfor k, v in y_train.items():\n",
    "\t\t\ty_train[k] = v.to(DEVICE)\n",
    "\t\t\n",
    "\t\ty_pred = model(X_train)\n",
    "\t\ty_pred = torch.softmax(y_pred, dim=2)\n",
    "\n",
    "\t\t# print(f\"{y_pred.size() = }\")\n",
    "\t\t# print(f\"{y_train['SCS'].size() = }\\n\")\n",
    "\n",
    "\n",
    "\t\tacc = torchmetrics.functional.accuracy(y_pred[:, :, :], y_train[\"SCS\"][:, :, :], task='multiclass', num_classes=3)\n",
    "\t\tprint(f\"Metric = {acc.item()}\\n\")\n",
    "\n",
    "\t\tf1 = torchmetrics.functional.f1_score(y_pred[:, :, :], y_train[\"SCS\"][:, :, :], task='multiclass', num_classes=3)\n",
    "\t\tprint(f\"Metric = {f1.item()}\\n\")\n",
    "\t\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
